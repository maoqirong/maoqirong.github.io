<!DOCTYPE html>
<!-- saved from url=(0029)https://cszhangtao.github.io/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  	<title>Qirong Mao | Jiangsu University</title>
  	<meta name="viewport" content="width=device-width, initial-scale=1">
 	 <!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
  	<link rel="stylesheet" href="./assets/main.css">
  	<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
 	 </head>
<script>
    var last = null;
    window.onload=function(){
        var a = document.getElementById("nav").getElementsByTagName("a");
        for(i=0,len=a.length;i<len;i++){
            a[i].onclick=function(){
                if(last){
                    last.style.backgroundColor="#4acaa8"
                }
                this.style.backgroundColor="hsla(164,69%,48%,1.00)"
                last=this;
            }
        }	 
    }
</script>
  	<body>

<!-- Header -->
<section id="header">
  	<header>
  	<span class="image avatar"><img src="./assets/img/12345.jpg" alt=""></span>
  	<h1 id="logo">
    Qirong Mao </h1>

  	</header>

  	<nav id="nav">
  	<ul>
    	<li><a href="#Introduction" class=""  id="Introduction-link" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);" class="active">Introduction</a></li>
    	<li><a href="#Research Overview" class=""  id="Research Overview-link" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">Research Overview</a></li>
		<li><a href="#Professional Service" class=""  id="Professional Service-link" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">Professional Service</a></li>
		<li><a href="#News" class=""  id="News-link" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">News</a></li>
		<li><a href="#Publications" id="Publications-link" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);" class="">Publications</a></li>
		<!--<li><a href="#Teaching">Teaching</a></li>-->
		<li><a href="#Funding" id="Funding-link" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);" >Funding</a></li>
		<li><a href="#Teaching" id="Teaching-link" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">Teaching</a></li>
		<li><a href="#Address" id="Address-link" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">Address</a></li>
  	</ul>
  	</nav>

  	<!--<footer>
  	<ul class="icons">
		<li><a href="www.sdu.edu.cn" class="icon fa-google"><span class="label">Twitter</span></a></li>
		<li><a href="#" class="icon fa-facebook"><span class="label">Facebook</span></a></li>
		<li><a href="#" class="icon fa-linkedin"><span class="label">Instagram</span></a></li>
		<li><a href="#" class="icon fa-github"><span class="label">Github</span></a></li>
		<li><a href="#" class="icon fa-envelope"><span class="label">Email</span></a></li>
  	</ul>
  	</footer>-->
</section>

<!-- Wrapper -->
<div id="wrapper">

	<!-- Main -->
	<div id="main">

	<!-- One -->
	<section id="Introduction">
		<div class="container">
			<header class="major">
			<h3><font color="#00008b">Dr. Qirong Mao </font></h3>
			</header>

			<p align="justify">Professor, School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang.</p>
			
			<p align="justify">Qirong received her MS and PhD degree in Computer Science and Technology from Jiangsu University, Zhenjiang, P. R. China in 2002 and 2009. She worked for one year at the Wayne State University and the University of Michigan as a visiting scholar advised by Dr. Ming Dong. She is currently a professor of the School of Computer Science and Communication Engineering, Jiangsu University. </p>
			
		</div>
	</section>

	<!-- Two -->
		<section id="Research Overview">
		<div class="container">
			<h3><font color="#00008b">Research Overview </font></h3>

			<p align="justify">Her research interests include affective computing, speech processing, pattern recognition, and multimedia analysis. Her research is supported by the Key Project of National Science Foundation of China (NSFC), Jiangsu province, and the Education Department of Jiangsu province. She has published over 50 technical articles, some of them in premium journals and conferences such as ACM Multimedia, CVPR, ICME, IEEE Transactions on Multimedia, Speech Communication, ICASSP etc.. She is a member of the IEEE. </p>

		</div>
	</section>

	<!-- Three-->
		<section id="Professional Service">
		<div class="container">
			<h3><font color="#00008b">Professional Service </font></h3>
			<p align="justify">
			 <ul>
				 <h4>Program Committee / Reviewer:</h4>
				 <ul>
				 <li>MIPR: 2018</li>
				 <li>BIGMM: 2018</li>
				 <li>ICME:2017</li>
				 </ul>

				<h4>Journal Reviewer:</h4>
				 <ul>
				 <li>IEEE Transactions on Affective Computing (IEEE-TAC)</li>
				 <li>Neural Networks (NEUNET)</li>
				 <li>IEEE Transactions on Audio, Speech and Language Processing (IEEE-TASL)</li>
				 <li>ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)</li>
				 <li>SCIENCE CHINA Information Sciences</li>
				 <li>Smart Health</li>
				 <li>Proceedings of the IEEE</li>
				 </ul>
				<h4>a senior member of the China Computer Federation</h4>
				<h4>a member of the IEEE and the ACM</h4>

			 </ul>

			</p>
			<p align="justify">I am looking for highly motivated Post doc./Phd students with strong background in Multimedia Analysis, Speech Processing, Programming, and Artificial Intelligence. We also warmly welcome undergraduate students who are interested in my research to join us as research assistant. Please feel free to contact me via emails on the page bottom.</p>


		</div>
	</section>


	<!-- Four -->
	<section id="News">
		<div class="container">
			<h3><font color="#00008b">News</font></h3>
				<ul>
				<li><font color="red">New!</font> [2019.10.23]. Our paper “<strong>Learning Disentanglement Representation for Acoustic Event Detection</strong>” has been represented on ACM Multimedia2019. <font color="red">Congratulations Lijian!</font></li>
				<li><font color="red">New!</font> [2019.09.23] Our paper “<strong>Triple attention network for sentimental visual question answering</strong>” has been accepted by Computer Vision and Image Understanding. <font color="red">Congratulations Ruwa!</font></li>
				<li><font color="red">New!</font>[2019.09.30] My Phd student Ling Zhou and Master student Qing Zhu received China National Scholarships 2019. <font color="red">Congratulations Ling and Qing!</font></li>
				<li><font color="red">New!</font>[2019.07.22]. Our paper: “<strong>Cross-Database Micro-Expression Recognition: A Style Aggregated and Attention Transfer Approach</strong>” has been represented in IEEE International Conference on Multimedia and Expo Workshops. <font color="red">Congratulations Ling!</font></li>
				<li><font color="red">New!</font>[2019.07.06] My PhD student, Feifei Zhang, successfully finished her PhD defense. She will join NLPR, Institute of Automation，Chinese Academy of Sciences as a Postdoctoral. <font color="red">Congratulations Feifei!</font></li>
				<li><font color="red">New!</font>[2019.07.06] My PhD student, Nelson Ruwa, successfully finished his PhD defense. <font color="red">Congratulations Ruwa!</font></li></li>
				<li><font color="red">New!</font>[2019.06.11]. Our paper “<strong>Dual Exclusive Attentive Transfer for Unsupervised Deep Convolutional Domain Adaptation in Speech Emotion Recognition</strong>” has been accepted by IEEE Access. <font color="red">Congratulations Elias!</font></li>

				<li><font color="red">New!</font>[2019.06.10]. My master student, Lijian Gao received the special offer from Nanjing Fenghuo Software Technology Co., Ltd.  <font color="red">Congratulations Lijian!</font></li>
				<li><font color="red">New!</font>[2019.05.14]. My PhD student, Ling Zhou ranked the third in the Micro-Expression Grand Challenge 2019. <font color="red">Congratulations Ling!</font></li>

				<li><font color="red">New!</font>[2019.04.09] My PhD student, Feifei Zhang has supported by 2019 postdoctoral innovation talent plan. <font color="red">Congratulations Feifei!</font></li>

				<li><font color="red">New!</font>[2019.03.20]. Our paper: “<strong>An emotion-based responding model for natural language conversation</strong>” has been published on World Wide Web. <font color="red">Congratulations Feng!</font></li>

				<li><font color="red">New!</font> [2019.02.22]. Our paper: “<strong>Mood-Aware Visual Question Answering</strong>” has been published in Neuro Computing. <font color="red">Congratulations Ruwa!</font></li>

				<li><font color="red">New!</font> [2018.12.12]. Our group are supported by the Key Project of National Natural Science Foundation of China.<font color="red"> Congratulations!</font></li>

				<li><font color="red">New!</font>[2018.11.20]. Our paper: “<strong>Cascaded Multi-level Transformed Dirichlet Process for Multi-pose Facial Expression Recognition</strong>” has been published on The Computer Journal. <font color="red">Congratulations Feifei!</font></li>

				<li><font color="red">New!</font>[2018.10.24]. Our paper: “<strong>Facial Expression Recognition in the Wild: A Cycle-Consistent Adversarial Attention Transfer Approach</strong>” has been represented on the Proc of 2018 ACM Multimedia Conference on Multimedia Conference (ACM Multimedia2018). <font color="red">Congratulations Feifei!</font></li>

				<li><font color="red">New!</font>[2018.06.22]. Our paper: “<strong>Joint Pose and Expression Modeling for Facial Expression Recognition</strong>” has been represented on the Proc. of the IEEE Conference on Computer Vision and Pattern Recognition 2018(CVPR2018). <font color="red">Congratulations Feifei!</font></li>

				<li><font color="red">New!</font>[2018.04.10]. Our paper: “<strong>Spatially Coherent Feature Learning for Pose-Invariant Facial Expression Recognition</strong>” has been published on ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM). <font color="red">Congratulations Feifei!</font></li>


				</ul>
		</div>
	</section>




	<!-- Five -->
	<section id="Publications">
		<div class="container">
			<h3 ><font color="#00008b">Publications </font></h3>
			<!--<a href="#" class="button">Google Scholar</a> <a href="#" class="button">Research Gate</a> -->
			<ul>
				<h4><font color="#00008b">2019</font></h4>
				<ul>
					<li>Lijian Gao, <strong>Qirong Mao(*)</strong>, Yu Jin, Ming Dong. On Learning Disentanglement Representation for Acoustic Event Detection. ACM International Conference on Multimedia, 2019, Nice, France.</li>
					<li>Nelson Ruwa, <strong>Qirong Mao</strong>, Liangjun Wang, Jianping Gou, Ming Dong. Mood-Aware Visual Question Answering, Neuro Computing, 2019, 330(22):  305-316.</li>
					<li>Nelson Ruwa,<strong>Qirong Mao</strong>, Hongjie Jia, Ming Dong. Triple attention network for sentimental visual question answering, Computer Vision and Image Understanding, 2019, (189), 1-10.</li>
					<li>Elias Nii Noi Ocquaye, <strong>Qirong Mao</strong>, Heping Song, Guopeng Xu, Yanfei Xue. Dual Exclusive Attentive Transfer for Unsupervised Deep Convolutional Domain Adaptation in Speech Emotion Recognition, IEEE Access, 2019, 7: 93847-93857. </li>
					<li>Feng Liu, <strong>Qirong Mao</strong>, Liangjun Wang, Nelson Ruwa, Jianping Gou, Yongzhao Zhan: An emotion-based responding model for natural language conversation. World Wide Web 22(2): 843-861 (2019).</li>
					<li>Ling Zhou, <strong>Qirong Mao(*)</strong>, Luoyang Xue, Dual-inception network for cross-database micro-expression recognition, Proc.-14th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2019, May 2019.</li>
					<li>Ling Zhou,<strong>Qirong Mao(*)</strong>, Luoyang Xue. Cross-Database Micro-Expression Recognition: A Style Aggregated and Attention Transfer Approach, Proceedings - 2019 IEEE International Conference on Multimedia and Expo Workshops, ICMEW 2019, p 102-107.</li>

				</ul>
				<h4><font color="#00008b">2018</font></h4>
				<ul>
					<li>Feifei Zhang, Tianzhu Zhang, <strong>Qirong Mao</strong>, Changsheng Xu, et al. Joint Pose and Expression Modeling for Facial Expression Recognition. Proc. of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 3359-3368. </li>
					<li>Feifei Zhang, Tianzhu Zhang, <strong>Qirong Mao</strong> et al. Facial Expression Recognition in the Wild: A Cycle-Consistent Adversarial Attention Transfer Approach. 2018 ACM Multimedia Conference on Multimedia Conference. ACM, 2018: 126-135.</li>
					<li><strong>Qirong Mao</strong> , Feifei Zhang, Liangjun Wang, Sidian Luo, Ming Dong. Cascaded Multi-level Transformed Dirichlet Process for Multi-pose Facial Expression Recognition. The Computer Journal, 2018, 11(61): 1605–1619.</li>
					<li>Feifei Zhang, <strong>Qirong Mao</strong> , Xiangjun Shen, Yongzhao Zhan, Ming Dong, et al. Spatially Coherent Feature Learning for Pose-Invariant Facial Expression Recognition. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), 2018, 14(1s): 27.</li>
					<li>Elias Ocquaye, <strong>Qirong Mao</strong>, Guopeng Xu, Yanfei Xue. Coupled Unsupervised Deep Convolutional Domain Adaptation for Speech Emotion Recognition, 2018 Fourth IEEE International Conference on Multimedia Big Data (BigMM), 2018.</li>
					<li>Nelson Ruwa,<strong>Qirong Mao</strong>, Liangjun Wang, Ming Dong. Affective Visual Question Answering Network. MIPR, 2018: 170-173.</li>


				</ul>
				<h4><font color="#00008b">2017 and old</font></h4>
				<ul>
					<li><strong>Qirong Mao</strong>, Qiyu Rao, Yongbin Yu, Ming Dong. Hierarchical Bayesian Theme Models for Multipose Facial Expression Recognition, IEEE Transactions on Multimedia, 2017, 19(4):861 – 873.</li>
					<li><strong>Qirong Mao</strong>, Ming Dong, Zhengwei Huang, Yongzhao Zhan, Learning Salient Features for Speech Emotion Recognition Using Convolutional Neural Networks, IEEE Transactions on Multimedia, 2014, 16(8): 2203-2213.</li>
					<li><strong>Qirong Mao</strong>,  Guopeng Xu, Wentao Xue, Jianping Gou, Yongzhao Zhan. Learning Emotion-discriminative and Domain-invariant Features for Domain Adaptation in Speech Emotion Recognition, Speech Communication, 2017, 93:1-12. </li>
					<li>Feifei Zhang,<strong>Qirong Mao</strong>, Ming Dong, Yongzhao Zhan, Multi-pose Facial Expression Recognition Using Transformed Dirichlet Process, Proc. of the 2016 ACM on Multimedia, Amsterdam, The Netherlands, 2016,.10. 15 – 19. </li>
					<li>Zhengwei Huang，Ming Dong, <strong>Qirong Mao</strong>，Yongzhao Zhan, Speech Emotion Recognition Using CNN. Proc. of the 22th ACM International Conference on Multimedia，Orlando, FL, USA.，2014.11.3-2014.11.7. </li>
					<li><strong>Qirong Mao</strong>(#)(*), Xinyu Pan, Yongzhao Zhan, Using Kinect for real-time emotion recognition via facial expressions，Frontiers of Information Technology & Electronic Engineering, 2015, 16(4): 272-282.</li>
					<li>Zhengwei Huang, Wentao Xue,<strong>Qirong Mao</strong>, Yongzhao Zhan. Unsupervised domain adaptation for speech emotion recognition using PCANet. Multimedia Tools  Applications.  2017,76(5): 6785-6799.</li>
					<li><strong>Qirong Mao</strong>(#)(*), Xiaolei Zhao, Zhengwei Huang, Yongzhao Zhan, Speaker- independent speech emotion recognition by fusion of functional and ccompanying paralanguage features, Journal of Zhejiang University-Science C(Computers and Electronics), 2013, 14(7):573-582.</li>
					<li>Feifei Zhang, Yongbin Yu, <strong>Qirong Mao</strong>(*), Yongzhao Zhan. Pose-robust Feature Learning for Facial Expression Recognition, Frontiers of Computer Science in China, 2016, 10(5): 1-13.</li>
					<li>Zhengwei Huang(#), Wentao Xue, <strong>Qirong Mao</strong>(*), Yongzhao Zhan, Speech emotion recognition with unsupervised feature learning, Frontiers of Information Technology & Electronic Engineering, 2015, 16(5): 358-366. </li>
					<li><strong>Qirong Mao</strong>(#*), Suli Hu, Haihe Wang, Yongzhao Zhan, A Semi-Supervised Recognition Method Based on Probability Distance Manifold Learning and Graph-Model, Journal of Computational & Theoretical Nanoscience, 2014, 11(2):303-309. </li>
					<li>Li Wang，<strong>Qirong Mao</strong>(*), The Dimensional Emotion Prediction of Multiple Cues and Modalities Using Improved KNN algorithm, Information & Computational Science, 2014,16(1): 5707-5716. </li>
					<li><strong>Qirong Mao</strong>(#)(*)，Wentao Xue，Qiyu Rao，Feifei Zhang，Yongzhao Zhan, Domain Adaption for Speech Emotion Recognition by Sharing Priors Between Related Sources and Target. Proc. of the 41st IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2016), Shanghai, 2016.3.20-2016.3.25.</li>
					<li>Qiyu Rao(#)，Xing Qu，<strong>Qirong Mao</strong>(*)，Yongzhao Zhan, Multi-pose facial expression recognition based on SURF boosting, Proc. of 2015 International Conference on Affective Computing and Intelligent Interaction (ACII)，Xi'an China，2015.9.21-2015.9.24. </li>
					<li>Wentao Xue(#)，Zhengwei Huang，Luo Xin，<strong>Qirong Mao</strong>(*), Learning speech emotion features by joint disentangling-discrimination, Proc. of the 2015 International Conference on Affective Computing and Intelligent Interaction (ACII)，Xi’an，2015.9.21-2015.9.24. </li>
					<li>Ebenezer, Owusu, Yongzhao Zhan(*), <strong>Qirong Mao</strong>. A neural-AdaBoost based facial expression recognition system，Expert Systems with Applications, 2014, 41(7):3383-3390. </li>
					<li>Owusu, Ebenezer, Yonzhao Zhan,<strong>Qirong Mao</strong>. An SVM-AdaBoost facial expression recognition system，Applied Intelligence，2014，40(3)：536-545.</li>
					<li>Xiaobo Chen, Jian Yang(*), <strong>Qirong Mao</strong>. Regularized least squares fisher linear discriminant with applications to image recognition，Neurocomputing，2013，122:512-534.</li>


				</ul>

			</ul>


		</div>
	</section>






	<!-- Six -->
	<section id="Funding">
		<div class="container">
			<h3><font color="#00008b">Funding</font></h3>
			<ul>
			<li><strong>Speaker Recognition and Keywords-related Information Retrieval in Complex Conversation Environment</strong> <br>supported by the Key Project of National Natural Science Foundation of China</br>Jan. 2019 - Dec. 2022, PI</li>

			<li><strong>Complex Emotion Discovery and Analysis from Big Audio-vision Data</strong> <br>supported by the General Project of National Natural Science Foundation of China</br>Jan. 2017 - Dec. 2020, PI</li>

			<li><strong>sponsored by Qing Lan Talent Program of Jiangsu Province</strong> <br>Jun. 2018-May. 2021, PI</li>

</ul></div></section>


			<!-- seven -->
	<section id="Teaching">
		<div class="container">
			<h3><font color="#00008b">Teaching</font></h3>
				<ul>
				<li>Operating System</li>
				<li>Machine Learning</li>
				<li>(Advanced) Human Computer Interaction</li>
				<li>Introduction to intelligent science and technology</li>
				</ul>
		</div>
	</section>


		<section id="Address">
		<div class="container">
			<h3><font color="#00008b">Address</font></h3>
			<p><strong>Office</strong>: 515, School of Computer Science and Communication Engineering Building
				<br>&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp  301,Xuefu Road, Jingkou District,
				<br>&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp Zhenjiang, Jiangsu, China, 212013
</p>
		<p><strong>Email</strong>:  mao_qr@ujs.edu.cn</p>
 <p><br><br><br><br><br><br><br><br><br><br><br><br><br></p>

		</div>
	</section>


		<!-- Scripts -->
			<script src="./Zhang Tao&#39;s Homepage_files/jquery.min.js.下载"></script>
			<script src="./Zhang Tao&#39;s Homepage_files/jquery.scrollzer.min.js.下载"></script>
			<script src="./Zhang Tao&#39;s Homepage_files/jquery.scrolly.min.js.下载"></script>
			<script src="./Zhang Tao&#39;s Homepage_files/skel.min.js.下载"></script>
			<script src="./Zhang Tao&#39;s Homepage_files/util.js.下载"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="./Zhang Tao&#39;s Homepage_files/main.js.下载"></script>
